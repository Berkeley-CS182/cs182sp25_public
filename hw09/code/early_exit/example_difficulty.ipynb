{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Deep Learning Through the Lense of Example Difficulty\n",
    "\n",
    "Much of this homework is inspired by the following paper:\n",
    "https://arxiv.org/abs/2106.09647\n",
    "\n",
    "Deep Learning Practioners have recognized that within the same task, particular examples in the test set can actually be harder to perform predictions on that others. Why is that? What kinds of things are easier to learn? We explore the notion of example difficulty, proposed by Baldock et. al. that will allow us to perform deeper investigations on the topic.\n",
    "\n",
    "\n",
    "## Defining of Prediction Depth\n",
    "\n",
    "Consider a N-Layer neural network, with KNN Classifiers after each layer. \n",
    "\n",
    "$K_L(x)$ is the classification of the KNN after layer $L$\n",
    "\n",
    "We will say that a prediction is made at depth $L$ if $L$ is the minimum value such that $m > L$ implies $K_m(x) = K_N(x)$ \n",
    "\n",
    "Essentially, we make a prediction at depth $L$ if after that layer, the classifications stay consistent.\n",
    "\n",
    "\n",
    "## Why Prediction Depth Matters\n",
    "\n",
    "Prediction depth can be viewed as a proxy for how hard a particular training example is. In this notebook we will explore the relation to what appears to be qualitatively difficult and prediction depth.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Setup\n",
    "\n",
    "We will first train a ResNet-18. Once trained, we will pass in all the training data once more to get the intermediate representations after each layer. We will use these representations to train a KNN at each layer to classify data. We will then use the trained KNN classifiers on the evaluation/test data to determine prediction depth and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Glance at the Data\n",
    "\n",
    "Let's take a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "shapes = ['circle', 'square', 'rectangle', 'right_triangle', 'heart', 'ellipse']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please download the data from the website and drag it into this folder. \n",
    "\n",
    "We start with the standard dataloading pytorch definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('data.npy', allow_pickle=True).item()\n",
    "x_tensor = torch.FloatTensor(data['x'])\n",
    "y_tensor = torch.LongTensor(data['y'])\n",
    "dataset = torch.utils.data.TensorDataset(x_tensor, y_tensor)\n",
    "trainloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, num_workers=2, shuffle=True)\n",
    "\n",
    "test_data = np.load('test_data.npy', allow_pickle=True).item()\n",
    "x_tensor = torch.FloatTensor(test_data['x'])\n",
    "y_tensor = torch.LongTensor(test_data['y'])\n",
    "test_dataset = torch.utils.data.TensorDataset(x_tensor, y_tensor)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, num_workers=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_indices = np.random.choice([i for i in range(6000)], 9, replace=False)\n",
    "\n",
    "plt.figure(figsize=(9, 9))\n",
    "\n",
    "for i, index in enumerate(random_indices, 1):\n",
    "    x, y = test_data['x'][index], test_data['y'][index]\n",
    "    \n",
    "    plt.subplot(3, 3, i)  # 2 rows and 5 columns of subplots\n",
    "    plt.imshow(x.reshape((32, 32, 1)), cmap='gray')\n",
    "    plt.axis('off')  # Turn off axis numbers and ticks\n",
    "    plt.title(f'Shape: {shapes[y]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Difficulty\n",
    "\n",
    "What kind of properties do you think will make an example from this dataset difficult?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a ResNet\n",
    "\n",
    "We begin by training a standard ResNet-18 to classify each example by its shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),                       # Convert arrays to PIL images\n",
    "    transforms.Grayscale(num_output_channels=3),   # Convert grayscale to RGB\n",
    "    transforms.Resize((224, 224)),                 # Resize all images to 224x224\n",
    "    transforms.ToTensor(),                      # Convert the images to PyTorch tensors\n",
    "])\n",
    "from copy import deepcopy\n",
    "resnet_dataset = deepcopy(dataset)\n",
    "resnet_dataset.transform = transform\n",
    "\n",
    "resnet_trainloader = torch.utils.data.DataLoader(resnet_dataset, batch_size=batch_size, num_workers=2, shuffle=True)\n",
    "x_tensor = torch.FloatTensor(test_data['x'])\n",
    "y_tensor = torch.LongTensor(test_data['y'])\n",
    "test_dataset = torch.utils.data.TensorDataset(x_tensor, y_tensor)\n",
    "resnet_test_dataset = deepcopy(test_dataset)\n",
    "resnet_test_dataset.transform = transform\n",
    "resnet_testloader = torch.utils.data.DataLoader(resnet_test_dataset, batch_size=batch_size, num_workers=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = torchvision.models.resnet18()\n",
    "num_ftrs = resnet.fc.in_features\n",
    "resnet.fc = torch.nn.Linear(num_ftrs, 6)\n",
    "resnet = resnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "resnet_optimizer = optim.Adam(resnet.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0\n",
    "resnet_losses = []\n",
    "for epoch in tqdm(range(10)):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(resnet_trainloader, 0):\n",
    "        step += 1\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        inputs = inputs.unsqueeze(1)\n",
    "        inputs = inputs.repeat(1, 3, 1, 1)\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        resnet_optimizer.zero_grad()\n",
    "        \n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = resnet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        resnet_optimizer.step()\n",
    "        resnet_losses.append(loss.item())\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 50 == 49:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1}] loss: {running_loss / 20:.3f}')\n",
    "            running_loss = 0.0\n",
    "        \n",
    "        \n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finished Training\n",
    "\n",
    "Now that we've finished training our ResNet, let's visualize the training curve to make sure we've trained to convergence. 10 epochs should be enough\n",
    "\n",
    "Note: Analyzing example difficulty without training to convergence would be faulty. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(len(resnet_losses))], resnet_losses)\n",
    "plt.xlabel('Gradient Steps')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.title('Training Loss vs Gradient Steps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Set\n",
    "\n",
    "But did it actually learn? What is the evaluation accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.eval()\n",
    "\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    total_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(resnet_test_dataset, 0)):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            \n",
    "            inputs, labels = inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            \n",
    "            inputs = inputs.unsqueeze(0).unsqueeze(0)\n",
    "            inputs = inputs.repeat(1, 3, 1, 1)\n",
    "            inputs = inputs.to(device)\n",
    "            \n",
    "            \n",
    "            # forward + backward + optimize\n",
    "            outputs = resnet(inputs)\n",
    "            \n",
    "            indices = torch.argmax(outputs, dim=1)\n",
    "            \n",
    "            total_correct += torch.sum(labels == indices)\n",
    "            \n",
    "print(total_correct)\n",
    "\n",
    "\n",
    "print('Finished Training')\n",
    "print(f'Accuracy: {total_correct/6000 * 100} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capturing Activations\n",
    "\n",
    "We will need to capture the activations to run KNN. We can do this in pytorch by attaching forward hooks. We need to this since we can't directly edit the model, as the code is abstracted away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = dict()\n",
    "resnet_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_hook(layer_num, activations):\n",
    "    def hook(module, input, output):\n",
    "        if layer_num + 1 not in activations:  \n",
    "            if layer_num == 0:\n",
    "                activations[layer_num] = [input[0]]\n",
    "            activations[layer_num + 1] = [output]\n",
    "        else:\n",
    "            if layer_num == 0:\n",
    "                activations[layer_num].append(input[0])\n",
    "            activations[layer_num + 1].append(output)\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_num = 0\n",
    "handles = []\n",
    "for layer in resnet.children():\n",
    "    handles.append(layer.register_forward_hook(forward_hook(layer_num, activations)))\n",
    "    layer_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in tqdm(range(1)):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(resnet_trainloader, 0):\n",
    "        step += 1\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        inputs = inputs.unsqueeze(1)\n",
    "        inputs = inputs.repeat(1, 3, 1, 1)\n",
    "        inputs = inputs.to(device)\n",
    "        resnet_labels.append(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        with torch.no_grad():\n",
    "        # forward + backward + optimize\n",
    "            outputs = resnet(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training KNN Classifiers and Removing Hooks\n",
    "\n",
    "Let's train the classifiers with the activations that we've collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in activations:\n",
    "    \n",
    "    activations[layer] = torch.cat(activations[layer], dim=0)\n",
    "    activations[layer] = torch.flatten(activations[layer], start_dim=1)\n",
    "    \n",
    "resnet_labels = torch.cat(resnet_labels, dim=0)\n",
    "\n",
    "resnet_classifiers = [KNeighborsClassifier(n_neighbors=30) for _ in range(len(activations))]\n",
    "\n",
    "for i, neigh in enumerate(resnet_classifiers):\n",
    "    neigh.fit(activations[i].cpu().numpy(), resnet_labels.cpu().numpy())\n",
    "\n",
    "for handle in handles:\n",
    "    handle.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting Test Set Activations\n",
    "\n",
    "Now we want to check the predictions of the test set examples. Using the activations and trained KNN's we can predict the output at each layer in the ResNet to determine things like prediction depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_activations = dict()\n",
    "test_resnet_labels = []\n",
    "layer_num = 0\n",
    "for layer in resnet.children():\n",
    "    layer.register_forward_hook(forward_hook(layer_num, test_activations))\n",
    "    layer_num += 1\n",
    "\n",
    "\n",
    "    test_resnet_labels = []\n",
    "for epoch in tqdm(range(1)):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(resnet_testloader, 0):\n",
    "        step += 1\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        inputs = inputs.unsqueeze(1)\n",
    "        inputs = inputs.repeat(1, 3, 1, 1)\n",
    "        inputs = inputs.to(device)\n",
    "        test_resnet_labels.append(labels)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        with torch.no_grad():\n",
    "        # forward + backward + optimize\n",
    "            outputs = resnet(inputs)\n",
    "            \n",
    "        if i == 0:\n",
    "            correct = torch.argmax(outputs, dim=1) == labels\n",
    "        else:\n",
    "            correct = torch.cat((correct, torch.argmax(outputs, dim=1) == labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in test_activations:\n",
    "    \n",
    "    test_activations[layer] = torch.cat(test_activations[layer], dim=0)\n",
    "    test_activations[layer] = torch.flatten(test_activations[layer], start_dim=1)\n",
    "    \n",
    "test_resnet_labels = torch.cat(test_resnet_labels, dim=0)\n",
    "knn_outputs = [knn.predict(test_activations[i].cpu().numpy()) for i, knn in tqdm(enumerate(resnet_classifiers))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Prediction depths\n",
    "\n",
    "We will need a function to find the prediction depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_constant_index(row):\n",
    "\n",
    "    \"\"\"\n",
    "    Input: [Knn(L) for L in 1...N]\n",
    "    Output: Prediction  depth\n",
    "    \"\"\"\n",
    "    # Start from the end of the row\n",
    "    value = row[-1]\n",
    "    for i in range(len(row)-2, -1, -1): # iterate backwards\n",
    "        if row[i] != value:\n",
    "            return i+1\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparations for Analysis\n",
    "\n",
    "We need a few things before we conduct some analysis\n",
    "\n",
    "Predictions[i][j] = a numpy array containing the knn outputs of data point i at layer j\n",
    "\n",
    "indices[i] = prediction depth of data point i\n",
    "\n",
    "total_accuracy_list[i] = The probability of correctness by the end, if prediction depth was layer i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array(knn_outputs)\n",
    "indices = np.apply_along_axis(find_constant_index, axis=0, arr=predictions)\n",
    "correct = correct.cpu().numpy()\n",
    "prediction_layer_list = []\n",
    "for num in range(11):  # Numbers 0-9\n",
    "    temp_indices = np.where(indices == num)[0]\n",
    "    prediction_layer_list.append(temp_indices.tolist())\n",
    "total_accuracy_list = {}\n",
    "for i, layer in enumerate(prediction_layer_list):\n",
    "    if layer != []:\n",
    "        total_accuracy_list[i] = (np.sum(correct[layer])/len(layer), len(layer)/6000)\n",
    "    else:\n",
    "        total_accuracy_list[i] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Histogram of Prediction Layers\n",
    "\n",
    "**The below visualization shows how many of each data point had prediction layer 0, for instance. If there were 500 examples that had prediction layer 1, this means that the KNN outputs do not change after layer 1 for 500 images. This could be interpreted as there was enough information at layer 1 to determine the class of the image with high confidence, and that the extra computation of the resnet was not necessary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(indices, bins=[i for i in range(12)], weights=[1 for _ in range(6000)])\n",
    "plt.xlabel('Prediction Layer')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of Prediction Layers for a ResNet-18 on the Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Output Accuracy vs Prediction Layer\n",
    "\n",
    "**The below visualization shows the average accuracy of ResNet classification on points that exited at layer L. Notice that test examples that had lower prediction layer generally had higher accuracy from the ResNet. Note that the accuracy is from the predictions at the end of the ResNet, not the KNN classifiers. Prediction layer is still determined by the outputs of the KNN classifiers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(11) if total_accuracy_list[i] is not None], [ total_accuracy_list[i][0]  for i in range(11) if total_accuracy_list[i] is not None])\n",
    "plt.xlabel('Prediction Layer')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs Prediction Layer of an Resnet18 with KNN Classifiers on the Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Easy and Hard Examples\n",
    "\n",
    "Let's try to find some patterns in what might make an easy example different than a hard example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "easiest_examples = prediction_layer_list[0]\n",
    "hardest_examples = prediction_layer_list[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Easy Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "random_indices = np.random.choice(easiest_examples, 10, replace=False)\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "for i, index in enumerate(random_indices, 1):\n",
    "    x, y = test_data['x'][index], test_data['y'][index]\n",
    "    \n",
    "    plt.subplot(2, 5, i)  # 2 rows and 5 columns of subplots\n",
    "    plt.imshow(x.reshape((32, 32, 1)), cmap='gray')\n",
    "    plt.axis('off')  # Turn off axis numbers and ticks\n",
    "    plt.title(f'Shape: {shapes[y]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_indices = np.random.choice(hardest_examples, 10, replace=False)\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "for i, index in enumerate(random_indices, 1):\n",
    "    x, y = test_data['x'][index], test_data['y'][index]\n",
    "    \n",
    "    plt.subplot(2, 5, i)  # 2 rows and 5 columns of subplots\n",
    "    plt.imshow(x.reshape((32, 32, 1)), cmap='gray')\n",
    "    plt.axis('off')  # Turn off axis numbers and ticks\n",
    "    plt.title(f'Shape: {shapes[y]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can you spot a difference\n",
    "\n",
    "What would make these hard vs easy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_shapes = []\n",
    "for layer in prediction_layer_list:\n",
    "    prediction_shapes.append([])\n",
    "    for index in layer:\n",
    "        prediction_shapes[-1].append(test_data['y'][index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What kinds of Shapes Exit at each Layer?\n",
    "\n",
    "**At each prediction layer, there may be different classes of shapes that are more common to appear. The following visualization shows at each layer, what is the distribution and count of the classes of shapes that will have prediction layer L**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = prediction_shapes\n",
    "\n",
    "# Adjust to 6 rows and 2 columns for 11 plots + 1 empty\n",
    "fig, axs = plt.subplots(6, 2, figsize=(10, 14))\n",
    "\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    if i < len(data):  # Check if current index is within data's length\n",
    "        hist = [shapes[j] for j in data[i]]\n",
    "        for j in range(len(hist)):\n",
    "            if hist[j] == 'right_triangle':\n",
    "                hist[j] = 'triangle'\n",
    "        ax.hist(hist, bins=15)\n",
    "        ax.set_title(f'Layer {i}')\n",
    "    else:\n",
    "        ax.axis('off')  # Turn off the axis for the last empty plot\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the empirical prediction layer distribution for each Shape?\n",
    "\n",
    "\n",
    "**Each shape may have a different distribution of layers that they exit on. For instance, one might think that triangles are harder to classify, and therefore more of the distribution mass would be towards the later layers. We aim to show, for each shape, the distribution of what prediction layers the shape generally tended to**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = []\n",
    "data = [np.array(d) for d in data]\n",
    "for i in range(6):\n",
    "    frequency.append(dict())\n",
    "    for j in range(10):\n",
    "        frequency[-1][j] = np.sum(data[j] == i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2, figsize=(10, 12))\n",
    "\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    categories, counts = zip(*frequency[i].items())\n",
    "    ax.bar(categories, counts)\n",
    "    ax.set_title(shapes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Input Layer\")\n",
    "print('________________________--')\n",
    "for child in resnet.children():\n",
    "    print(child)\n",
    "    print('________________________--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patterns\n",
    "\n",
    "What kinds of patterns do you notice? Based on the composition of the layers, does it make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concluding Thoughts\n",
    "\n",
    "From what you witnessed in this homework, what can you say about example difficulty? How can we come up with better metrics of example difficulty? Why does it even matter? What are some possible applications of this line of work? In the next section of the homework, we will answer some of these questions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
