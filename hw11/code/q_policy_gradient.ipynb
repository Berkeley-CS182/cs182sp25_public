{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0sYcYdrmRWD"
   },
   "source": [
    "#**Q. Zero order optimization (Policy Gradient)**\n",
    "\n",
    "We will now talk about $0^{th}$ order optimization, also known as Policy Gradient in a Reinforcement Learning context. Although this method is primarily used in an RL context we will be adapting this method to do $0^{th}$ order optimization on a Neural Network.\n",
    "\n",
    "$k^{th}$ order optimization means that in the optimization, we use a $k^{th}$ order derivative ($\\frac{δL^k}{δ^kw}$) to do the optimization. So we can see that gradient descent is a first order optimization method, while Newton's method is a second order optimization method.\n",
    "\n",
    "Polciy gradient is a $0^{th}$ order optimization method - which means that you use no derivative for the optimzation. This is used in contexts in which the loss is a **blackboxed** function, hence propogating a gradient through it is impossible.\n",
    "\n",
    "Policy gradient at a high level approximates the gradient and then does gradient descent using this approximated gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7ZG9BYysble"
   },
   "source": [
    "##**a) A handy derivation**\n",
    "Prove that $p_{\\theta}(x) \\nabla_θlog(p_{\\theta}(x)) = \\nabla_θp_{\\theta}(x)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moPJUT6TtCPy"
   },
   "source": [
    "###**Answer:** \n",
    "\n",
    "$p_{\\theta}(x) \\nabla_θlog(p_{\\theta}(x)) = p_{\\theta}(x) \\frac{\\nabla_θp_{\\theta}(x)}{p_{\\theta}(x)} = \\nabla_θp_{\\theta}(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z67IBdNyvuKJ"
   },
   "source": [
    "##**b) Approximating the derivative**\n",
    "Let's say we have a neural network $f(x)$ which takes in a $x$ and uses the weights($w$) to output 2 logits <br> ($P = [P(y = 0)$, $P(y = 1)]$). <br> Let $p(x, y)$ be the joint distribution of the input and output data according to **our model**. Hence $p_w(x, y) = p(x)p_w(y|x)$, where p(x) is the ground distribution of x, while $p_w(y|x) = f(x)[y]$ is what our model predicts. \n",
    "<br><br>\n",
    "\n",
    "Similarly we have a **blackboxed** loss function $L(x, f(x))$ which outputs a loss. <br>\n",
    "For example if i wanted to learn to classify y = 1 if x > 5 and y = 0 otherwise, L(4, (0.1, 0.9)) would be small while L(4, (0.9, 0.1)) would be very high. As we already discussed, since this loss is blackboxed we can't take the derivative through it.\n",
    "<br><br>\n",
    "We want to optimize the following objective function <br>\n",
    "$w^* = argmin_wJ(w)$ <br> where $J(w) = E_{(x, f(x)) \\sim p_w(x, y)}[L(x, f(x))]$. \n",
    "<br>\n",
    "To do this optimization we want to approximate $\\nabla_{w} J(w)$ so that we could use an optimization method like gradient descent to find $w^*$ \n",
    "<br><br>\n",
    "**Prove that $\\nabla_{w} J(w)$ can be approximated as $\\frac{1}{N}∑_{i=1}^{i=N}(\\nabla_wlog(p_w(y_i|x_i))L(x_i, f(x_i))$**\n",
    "<br><br>\n",
    "**HINTS:**\n",
    "<ol>\n",
    "<li>Try creating a $\\tau = (x, f(x))$</li>\n",
    "<li>$E[X] = \\int_xxP(X=x)dx$ </li>\n",
    "<li>Use the result from part a which was $p_{\\theta}(x) \\nabla_θlog(p_{\\theta}(x)) = \\nabla_θp_{\\theta}(x)$</li>\n",
    "<li>$p_w(x, y) = p(x)p_w(y|x)$</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SeFtCU0QwWe4"
   },
   "source": [
    "###**Answer:**\n",
    "$w^* = argmin_wE_{(x, f(x)) \\sim p_w(x, y)}[L(x, f(x))]$. \n",
    "<br><br><br>\n",
    "\n",
    "We call $J(w) = E_{(x, f(x)) \\sim p_w(x, y)}[L(x, f(x))]$ and $\\tau = (x, f(x))$\n",
    "<br><br><br>\n",
    "\n",
    "$J(w) = E_{\\tau \\sim p_w(\\tau)}[L(\\tau)] = ∫_{\\tau}p_w(\\tau)L(\\tau)d\\tau$\n",
    "<br><br><br>\n",
    "\n",
    "\n",
    "Hence $\\nabla_{w} J(w) = ∫_\\tau(\\nabla_wp_w(\\tau))L(\\tau)d\\tau$ <br><br>\n",
    "&emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &nbsp;\n",
    "$= ∫_\\tau(\\nabla_wlog(p_w(\\tau)))p_w(\\tau)L(\\tau)d\\tau$ &emsp; &emsp; &emsp; (Using part a)\n",
    "<br><br> &emsp; &emsp; &emsp; &emsp; &emsp; &emsp; &nbsp;\n",
    " $ = E_{\\tau \\sim p_w(\\tau)}[(\\nabla_wlog(p_w(\\tau))L(\\tau)]$\n",
    "<br><br><br>\n",
    "We know that $\\nabla_wlog(p_w(\\tau)) = \\nabla_w[log(p(x)) + log(p_w(y|x))]$ <br><br>Since $p(x)$ does not depend on $w$ we can simplify this to $\\nabla_wlog(p_w(y|x))$\n",
    "<br><br><br>\n",
    "Hence $\\nabla_{w} J(w) = E_{\\tau \\sim p_w(\\tau)}[(\\nabla_wlog(p_w(\\tau))L(\\tau)] = E_{\\tau \\sim p_w(\\tau)}[(\\nabla_wlog(p_w(y|x))L(x, f(x))]$ <br><br> which can be approximated as $\\frac{1}{N}∑_{i=1}^{i=N}(\\nabla_wlog(p_w(y_i|x_i))L(x_i, f(x_i))$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B-MjEVGPtRzs"
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch as torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VR8R_l98EFZ1",
    "outputId": "bd4be85f-e448-4e56-c6a8-f8aa5c6cfe20"
   },
   "outputs": [],
   "source": [
    "# Determine the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hodmio2pO3qO"
   },
   "source": [
    "### Data Generation\n",
    "\n",
    "In this question, each datapoint is a 8 dimensional vector assigned to one of the four labels depending on their distance to two points $\\mathbf{1}$ and $-\\mathbf{1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-KaLm2kJRBl6"
   },
   "outputs": [],
   "source": [
    "def generate_data(num_samples, input_dim):\n",
    "    @torch.no_grad()\n",
    "    def true_y(x):\n",
    "        dp = ((x - 1) ** 2).sum(dim=-1)\n",
    "        dn = ((x + 1) ** 2).sum(dim=-1)\n",
    "        zp = dp <= input_dim * 2.5\n",
    "        zn = dn <= input_dim * 2.5\n",
    "\n",
    "        return torch.stack([\n",
    "            zp & zn,\n",
    "            zp & ~zn,\n",
    "            ~zp & zn,\n",
    "            ~zp & ~zn\n",
    "        ], dim=1).long().argmax(dim=-1)\n",
    "    \n",
    "    x = torch.rand((num_samples, input_dim)) * 4.4 - 2.2\n",
    "    y = true_y(x)\n",
    "    return x, y, true_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FR-LIF0zT2nF"
   },
   "source": [
    "Here is a visualization when the input dimension is 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "nZWEvF3AShvQ",
    "outputId": "4a2faa74-f968-4d7f-9c96-41d71104252a"
   },
   "outputs": [],
   "source": [
    "x, y, true_y = generate_data(1000, 2)\n",
    "plt.scatter(x[:, 0].numpy(), x[:, 1].numpy(), c=y.numpy(), s=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aiT8Fs2cT78n"
   },
   "source": [
    "Let's generate data for input dimension of 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MVEPyZ_zSlM9"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(73)\n",
    "np.random.seed(73)\n",
    "x, y, true_y = generate_data(1000, 8)\n",
    "x_test, y_test, _ = generate_data(1000, 8)\n",
    "x, y = x.to(device), y.to(device)\n",
    "x_test, y_test = x_test.to(device), y_test.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kRgzpyAoVJo-"
   },
   "source": [
    "Here is the definition of our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T55pfCoiVNxw"
   },
   "outputs": [],
   "source": [
    "def get_model(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    return nn.Sequential(\n",
    "        OrderedDict(\n",
    "            [  # randomly initialized NN\n",
    "                ('fc1', nn.Linear(8, 32)),\n",
    "                ('relu1', nn.ReLU()),\n",
    "                ('output', nn.Linear(32, 4))]\n",
    "        )\n",
    "    ).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdbFgOdzVlU7"
   },
   "source": [
    "Here is the definition of our metric: accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qjdKq5OfVlzU"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def accuracy(model, x, y):\n",
    "    pred = torch.argmax(model(x), dim=1)\n",
    "    correct = torch.sum(pred == y).item()\n",
    "    acc = (correct / len(y)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8BJdcPMVVrJ"
   },
   "source": [
    "### Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WUtQM4nMVXw7"
   },
   "outputs": [],
   "source": [
    "lr = 0.002\n",
    "num_iters = 3000\n",
    "model = get_model(73)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "train_accs = []\n",
    "train_accs.append(accuracy(model, x, y))\n",
    "valid_accs = []\n",
    "valid_accs.append(accuracy(model, x_test, y_test))\n",
    "for epoch in range(num_iters):\n",
    "    logits = model(x)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    loss = criterion(logits, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_accs.append(accuracy(model, x, y))\n",
    "    valid_accs.append(accuracy(model, x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "yMz7-NzoVrSU",
    "outputId": "38723ec8-1f1f-4d61-f259-edcc3be43d05"
   },
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(len(train_accs))], train_accs, label=\"Train\")\n",
    "plt.plot([i for i in range(len(valid_accs))], valid_accs, label=\"Test\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\"Final test accuracy:\", valid_accs[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fRvOnAoUWvsc"
   },
   "source": [
    "### Policy Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Fqq_dJXW1RZ"
   },
   "outputs": [],
   "source": [
    "# Reward Oracle Function (Black-boxed)\n",
    "# This function calculates the reward, returning 3 for correct predictions and -1 for incorrect ones.\n",
    "# Usage guidelines:\n",
    "# - Call this function only; do not rely on its internal implementation details.\n",
    "# - Gradients are not calculated within this function due to the `@torch.no_grad()` decorator.\n",
    "@torch.no_grad()\n",
    "def reward_oracle(x, pred):\n",
    "    return torch.where(true_y(x) == pred, 3, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tanvyC33v9Pd"
   },
   "source": [
    "**Implement Policy Gradient Algorithm:** Based on the formulas derived in part (b), complete the policy gradient implementation. For this task, we will use the Adam optimizer and process the full dataset in a single batch. The reward oracle has been invoked for you in the provided code. Remember, do not use the true labels directly in your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v4vYya6_8xzQ"
   },
   "outputs": [],
   "source": [
    "lr = 0.002\n",
    "num_iters = 3000\n",
    "model = get_model(73)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "train_accs = []\n",
    "train_accs.append(accuracy(model, x, y))\n",
    "valid_accs = []\n",
    "valid_accs.append(accuracy(model, x_test, y_test))\n",
    "for epoch in range(num_iters):\n",
    "    logits = model(x)\n",
    "    logprob = F.log_softmax(logits, dim=-1)\n",
    "\n",
    "    predicted = logits.detach().argmax(dim=-1)\n",
    "    reward = reward_oracle(x, predicted)\n",
    "\n",
    "    ############################################################################\n",
    "    # TODO: Calculate the loss function of policy gradient\n",
    "    ############################################################################\n",
    "    ############################################################################\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_accs.append(accuracy(model, x, y))\n",
    "    valid_accs.append(accuracy(model, x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4U76UCDowoj7"
   },
   "source": [
    "#### Question\n",
    "\n",
    "**Include the screenshot of the accuracy plot** in your written assignment submission. With a correct implementation, you should observe an accuracy of approximately 90% after the final iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "Jh7PIkoikW2W",
    "outputId": "c8431ea0-ba52-482e-a8b2-f35a79650e0b"
   },
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(len(train_accs))], train_accs, label=\"Train\")\n",
    "plt.plot([i for i in range(len(valid_accs))], valid_accs, label=\"Test\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\"Final test accuracy:\", valid_accs[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJ_4aALnX7FR"
   },
   "source": [
    "#### Question\n",
    "\n",
    "**Compare the policy gradient and supervised learning approaches for this classification task, focusing on their convergence speed, stability, and final performance. Explain any observed differences.** Include your response to this question in your written assignment submission."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
